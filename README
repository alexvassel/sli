Задание

1. Получить информацию с сайтов ya.ru python.org ru.wikipedia.org c помощью параллельных запросов.
2. Из полученных результатов изъять содержимое заголовков страницы (тег title)
3. Отобразить полученные данные заголовках страниц на web странице.
4. Добавить возможность выбора сайтов и извлечения заголовков в web интерфейсе (то есть через админку).

Код выложить на bitbucket или github.


На основной странице отображаются адреса, помеченные в БД как show == True.
По клику на кнопку "получить заголовки" к серверу от JS уходит один запрос со списком всех id на странице.
По id из БД сервер получает конкретные адреса, и по каждому из них (если их уже не проверяли ранее, флаг - ready)
ицициирует запрос на получение html страницы в асинхронном режиме.
Получив ответ от удаленного сервера, Tornado выделяет title, записывает его в БД и помечает адрес как проверенный (ключ - ready).

JS каждые REQUESTS_INTERVAL миллисекунд по id на странице спрашивает у Tornado, получил ли последний тайтлы; по мере поступления ответов,
заголовки записываются в соответствующую ячейку таблицы. Когда все тайтлы получены, запросы прекращаются.

Страницы

/ - основная

/admin/ - главная админки
/admin/url/{{ id }}/ - редактирование конкретной страницы

/login - авторизация в админку, пускает с любым именем пользователя без пароля

БД

SQLITE

sli.sqlite

Структура

CREATE TABLE "url" ("id" INTEGER PRIMARY KEY  AUTOINCREMENT  NOT NULL  UNIQUE , "response" TEXT, "href" TEXT NOT NULL , "ready" BOOL NOT NULL  DEFAULT False, "show" BOOL NOT NULL  DEFAULT True)

Одна таблица url с полями:

1. id
2. href - адрес, по которому достается title
3. response - title от сервера, или ошибка
4. ready - была ли попытка достать title
5. show - показывать ли на главной странице
